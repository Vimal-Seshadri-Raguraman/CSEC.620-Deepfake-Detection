# -*- coding: utf-8 -*-
"""ML Final Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mkac0akUVoSsKDzryZNqqnm3Wu0qsHFg
"""

import json
import csv

# Load JSON data from file
with open('metadata.json', 'r') as json_file:
    data = json.load(json_file)

# Prepare data for CSV
csv_data = [['name', 'label', 'split', 'original']]

for video_name, video_info in data.items():
    label = video_info.get('label', 'N/A')
    split = video_info.get('split', 'N/A')
    original = video_info.get('original', 'N/A')
    csv_data.append([video_name, label, split, original])

# Write to CSV file
with open('output.csv', 'w', newline='') as csv_file:
    csv_writer = csv.writer(csv_file)
    csv_writer.writerows(csv_data)
import pandas as pd

# Read the CSV file into a DataFrame
df = pd.read_csv('output.csv')

# Print the first 10 lines of the DataFrame
print(df.head(10))

# Import necessary libraries
import os
import cv2
import pandas as pd
from google.colab import drive
from sklearn.model_selection import train_test_split

# Connect to Google Drive
drive.mount('/content/drive')

# Define paths to your data
train_videos_path = '/content/drive/MyDrive/Deep/Train'
test_videos_path = '/content/drive/MyDrive/Deep/Test'
csv_path = 'output.csv'

# Read labels from CSV
df = pd.read_csv(csv_path)

# Create folders to store frames
train_frames_path = '/content/drive/MyDrive/Deep/train_frames/'
test_frames_path = '/content/drive/MyDrive/Deep/test_frames/'
os.makedirs(train_frames_path, exist_ok=True)
os.makedirs(test_frames_path, exist_ok=True)

from google.colab.patches import cv2_imshow

# Function to extract frames from videos with a limit
def extract_frames_limit(video_path, output_folder, max_frames=2):
    video_capture = cv2.VideoCapture(video_path)
    success, image = video_capture.read()
    count = 0

    while success and count < max_frames:
        frame_path = os.path.join(output_folder, f"frame_{count}.jpg")
        cv2.imwrite(frame_path, image)

        # Display the extracted frame
        cv2_imshow(image)

        success, image = video_capture.read()
        count += 1

    print(f"Generated {count} frames for video: {video_path}")

# Extract frames from training videos
for video_filename in os.listdir(train_videos_path):
    video_path = os.path.join(train_videos_path, video_filename)
    extract_frames_limit(video_path, train_frames_path, max_frames=2)

# Extract frames from testing videos
for video_filename in os.listdir(test_videos_path):
    video_path = os.path.join(test_videos_path, video_filename)
    extract_frames_limit(video_path, test_frames_path, max_frames=2)

from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import os
import numpy as np
import pandas as pd

# Define image dimensions and other parameters
desired_height = 224
desired_width = 224
num_frames_per_video = 2  # Assuming you extracted 10 frames per video

# Function to load and preprocess an image
def preprocess_image(image_path):
    img = load_img(image_path, target_size=(desired_height, desired_width))
    img_array = img_to_array(img) / 255.0  # Normalize pixel values to [0, 1]
    return img_array

# Data Preprocessing
def prepare_data(data_frame, frames_path):
    X = []
    y = []

    for idx, row in data_frame.iterrows():
        class_label = row['label']
        video_path = frames_path  # Path to the folder containing all frames

        # Process each frame in the video
        frames = []
        for i in range(num_frames_per_video):
            frame_filename = f"frame_{i}.jpg"  # Without including video_id in the filename
            frame_path = os.path.join(video_path, frame_filename)

            # Preprocess the image
            frame = preprocess_image(frame_path)
            frames.append(frame)

        X.append(frames)
        y.append(class_label)

    return np.array(X), np.array(y)

# Split the data into training and testing sets
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# Now you can use the provided data preprocessing code
X_train, y_train = prepare_data(train_df, train_frames_path)
X_test, y_test = prepare_data(test_df, test_frames_path)

# Prepare training and testing data
X_train, y_train = prepare_data(train_df, train_frames_path)
X_test, y_test = prepare_data(test_df, test_frames_path)

# Display some information about the data
print("Shape of X_train:", X_train.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_test:", y_test.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout

# Adjust the number of frames per video based on your data
num_frames_per_video = 2

# Define the input shape based on your frame dimensions
input_shape = (num_frames_per_video, 224, 224, 3)

# Build the CNN model
model = Sequential()

# Reshape the input data to match the expected shape
model.add(Conv3D(32, kernel_size=(3, 3, 1), activation='relu', input_shape=input_shape, padding='same'))
model.add(MaxPooling3D(pool_size=(2, 2, 2)))


# Flatten layer to transition from convolutional to dense layers
model.add(Flatten())

# Dense layers
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))  # 1 neuron for binary classification (fake or real)

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Display the model summary
model.summary()

# Convert labels to integers (assuming 'REAL' is 0 and 'FAKE' is 1)
y_train = (y_train == 'FAKE').astype(int)
y_test = (y_test == 'FAKE').astype(int)

import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
# Train the model using X_train and y_train
# Assuming you have X_train, y_train, X_test, and y_test
history=model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

# Visualize training history
plt.figure(figsize=(12, 6))

# Plot training & validation accuracy values
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.show()
# Evaluate the model
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_acc}')

# Generate predictions
y_pred = model.predict(X_test)
y_pred_classes = (y_pred > 0.5).astype(int)

# Generate classification report
print("\nClassification Report:\n", classification_report(y_test, y_pred_classes))

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred_classes)
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False, annot_kws={"size": 16})
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()